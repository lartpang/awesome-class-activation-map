# Awesome-Class-Activation-Map

An awesome list of papers and tools about the class activation map (CAM) technology.

> Class activation maps could be used to interpret the prediction decision made by the convolutional neural network (CNN).
>
> <https://paperswithcode.com/method/cam>

## ðŸ“š Paper

### 2016

- [CAM] Learning Deep Features for Discriminative Localization | [CVPR 2016](https://doi.org/10.1109/CVPR.2016.319), [Arxiv 2015](https://arxiv.org/abs/1512.04150)
- [Grad-CAM] Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization | [Arxiv 2016](https://arxiv.org/abs/1610.02391), ICCV 2017, [IJCV 2019](https://doi.org/10.1007/s11263-019-01228-7)

### 2018

- [Grad-CAM++] Grad-CAM++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks | [WACV 2018](https://doi.org/10.1109/WACV.2018.00097)

### 2019

- [Smooth Grad-CAM++] Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models | [Arxiv 2019](https://arxiv.org/abs/1908.01224), Intelligent Systems Conference 2019

### 2020

- [Score-CAM] Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks | [CVPRW 2020](https://doi.org/10.1109/CVPRW50498.2020.00020), [Arxiv 2019](https://arxiv.org/abs/1910.01279)
- [Ablation-CAM] Ablation-CAM: Visual Explanations for Deep Convolutional Network via Gradient-free Localization | [WACV 2020](https://doi.org/10.1109/WACV45572.2020.9093360)
- [SS-CAM] SS-CAM: Smoothed Score-CAM for Sharper Visual Feature Localization | [Arxiv 2020](https://arxiv.org/abs/2006.14255)    
- [IS-CAM] IS-CAM: Integrated Score-CAM for axiomatic-based explanations | [Arxiv 2020](https://arxiv.org/abs/2010.03023)
- [XGrad-CAM] Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of CNNs | [Arxiv 2020](https://arxiv.org/abs/2008.02312), BMVC 2020 (Oral) | [Code](https://github.com/Fu0511/XGrad-CAM)
- [Eigen-CAM] Eigen-CAM: Class Activation Map using Principal Components | [Arxiv 2020](https://arxiv.org/abs/2008.00299), [IJCNN 2020](https://doi.org/10.1109/IJCNN48605.2020.9206626)

### 2021

- [Ablation-CAM++] Ablation-CAM++: Grouped Recursive Visual Explanations for Deep Convolutional Networks | [ICIP 2021](https://doi.org/10.1109/ICIP46576.2022.9897617)
- [Relevance-CAM] Relevance-CAM: Your Model Already Knows Where to Look | [CVPR 2021](https://doi.org/10.1109/CVPR46437.2021.01470)
- [Group-CAM] Group-CAM: Group Score-Weighted Visual Explanations for Deep Convolutional Networks | [Arxiv 2021](https://arxiv.org/abs/2103.13859) | [Code](https://github.com/wofmanaf/Group-CAM)
- [Integrated Grad-Cam] Integrated Grad-Cam: Sensitivity-Aware Visual Explanation of Deep Convolutional Networks Via Integrated Gradient-Based Scoring | [ICASSP 2021](https://doi.org/10.1109/ICASSP39728.2021.9415064)
- [LFI-CAM] LFI-CAM: Learning Feature Importance for Better Visual Explanation | [ICCV 2021](https://doi.org/10.1109/ICCV48922.2021.00139)
- [LayerCAM] LayerCAM: Exploring Hierarchical Class Activation Maps for Localization | [TIP 2021](https://doi.org/10.1109/TIP.2021.3089943)
- [CALM] Keep CALM and Improve Visual Feature Attribution | [Arxiv 2021](https://arxiv.org/abs/2106.07861), [ICCV 2021](https://doi.org/10.1109/ICCV48922.2021.00824) | [Code](https://github.com/naver-ai/calm)

### 2022

- [Abs-CAM] Abs-CAM: A Gradient Optimization Interpretable Approach for Explanation of Convolutional Neural Networks | [Arxiv 2022](https://arxiv.org/abs/2207.03648), [SIViP 2023](https://doi.org/10.1007/s11760-022-02313-0)
- [Recipro-CAM] Recipro-CAM: Fast gradient-free visual explanations for convolutional neural networks | [Arxiv 2022](https://arxiv.org/abs/2209.14074)

### 2023

- [Opti-CAM] Opti-CAM: Optimizing saliency maps for interpretability | [Arxiv 2023](https://arxiv.org/abs/2301.07002)

## ðŸ§° Tool

- [TorchCAM: class activation explorer](https://github.com/frgfm/torch-cam): Class activation maps for your PyTorch models (CAM, Grad-CAM, Grad-CAM++, Smooth Grad-CAM++, Score-CAM, SS-CAM, IS-CAM, XGrad-CAM, Layer-CAM)
